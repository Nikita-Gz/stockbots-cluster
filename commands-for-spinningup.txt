minikube ssh docker pull farberg/apache-hadoop:3.3.2 -p tradebots-cluster

helm repo add pfisterer-hadoop https://pfisterer.github.io/apache-hadoop-helm/
helm install --name hadoop pfisterer-hadoop/hadoop

helm repo add bitnami https://charts.bitnami.com/bitnami
helm install mongodb bitnami/mongodb --set volumePermissions.enabled=true --set auth.rootPassword=$env:MONGODB_ROOT_PASSWORD_ENV --set auth.username=user --set auth.password=$env:MONGODB_ROOT_PASSWORD_ENV --set auth.database=tradebots-db

hdfs has to be set up, including webhdfs

kubectl create namespace spark-jobs
k apply -f .\spark\service-accounts.yaml

kubectl apply -f https://raw.githubusercontent.com/volcano-sh/volcano/master/installer/volcano-development.yaml

kubectl edit configmap volcano-scheduler-configmap --namespace volcano-system
add preempt to the list of actions

# spark
helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator
kubectl create namespace spark-operator
helm install spark-operator spark-operator/spark-operator --namespace spark-operator --set sparkJobNamespace=default --set enableWebhook=true --set enableBatchScheduler=true

# testing postgresql

kubectl apply -f postgres-pv.yaml
kubectl apply -f postgres-pvc.yaml

# ok or mysql
helm install my-release bitnami/mysql


# apache airflow
helm repo add apache-airflow https://airflow.apache.org
helm upgrade --install airflow apache-airflow/airflow --namespace airflow --create-namespace
helm install postgresql bitnami/postgresql --version 12.1.0
